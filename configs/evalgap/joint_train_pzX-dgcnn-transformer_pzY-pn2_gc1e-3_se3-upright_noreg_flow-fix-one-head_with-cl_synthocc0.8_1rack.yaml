# Logging Settings
hydra: 
  run:
    dir: ${log_dir}/${experiment}/${now:%Y-%m-%d_%H%M%S}
  sweep:
    dir: ${log_dir}/${experiment}/sweep/${now:%Y-%m-%d_%H%M%S}
    subdir: ${hydra.job.num}

log_dir: /home/odonca/workspace/rpad/data/equivariant_pose_graph/logs
# log_dir: /media/jenny/cubbins-archive/jwang_datasets/home_backup/jwang/code/equivariant_pose_graph/logs 
experiment: residual_flow_occlusion
wandb_group: icra2024

image_logging_period: 1001
ckpt_save_freq: 5_000 # used to be 1_000
check_val_every_n_epoch: 5
plot_encoder_distribution: True

# Dataset Settings

# ACTION_CLASS = 0
# ANCHOR_CLASS = 1
# GRIPPER_CLASS = 2


# mug on 1 rack- use cloud_type=teleport
dataset_root: /home/odonca/workspace/rpad/data/equivariant_pose_graph/data/mug_place/train_data/renders
test_dataset_root: /home/odonca/workspace/rpad/data/equivariant_pose_graph/data/mug_place/test_data/renders

num_points: 1024
distractor_anchor_aug: False
ball_radius: 0.1
plane_standoff: 0.04
gradient_clipping: 0.001 # 1 # 0 or blank (None) is don't clip
synthetic_occlusion: 0.8


# mug on rack (2 rack fixed) - use cloud_type=teleport
# dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data_duprack_bothmugrack/renders
# test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/test_data_duprack_bothmugrack/renders

# num_points: 1024
# distractor_anchor_aug: False
# ball_radius: 0.1
# plane_standoff: 0.04
# gradient_clipping: 0.001 # 1 # 0 or blank (None) is don't clip
# synthetic_occlusion: False # 



# synthetic_occlusion: 0.8 #True # nonzero numbers are truth-y python values!!
# # synthetic_occlusion:  True


# # mug on rack aug inf - use cloud_type=teleport
# # dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data_duprack_bothmugrack/renders
# dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data/renders
# # dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data_2mug/renders
# # dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data_duprack_bothmugrack_1mug_num2/renders/
# # dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data_aug/renders/
# # dataset_root: /home/jenny/code/equivariant_pose_graph/data/train_data_aug_easy/renders/

# # test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/test_data_duprack_bothmugrack/renders
# test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/test_data/renders
# # test_datset_root: /home/jenny/code/equivariant_pose_graph/data/test_data_duprack_bothmugrack_1mug_0/renders
# # test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/test_data_aug/renders
# # test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/test_data_aug_easy/renders

# num_points: 1024
# distractor_anchor_aug: True
# ball_radius: 0.1
# plane_standoff: 0.04
# gradient_clipping: 1e-3 #0.001 #0.1 #0.001 # 1 # 0 or blank (None) is don't clip





# bottle on shelf
# dataset_root: /home/jenny/code/equivariant_pose_graph/data/bottle_place/bottle_train_data_ndf_cons_3/renders
# test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/bottle_place/bottle_test_new_3/renders
# num_points: 512
# distractor_anchor_aug: False
# ball_radius: 0.1
# plane_standoff: 0.02
# gradient_clipping: 1 # 1 # 0 or blank (None) is don't clip





# bowl on shelf
# dataset_root: /home/jenny/code/equivariant_pose_graph/data/bowl_place/bowl_train_data_ndf_cons_3/renders/
# test_dataset_root: /home/jenny/code/equivariant_pose_graph/data/bowl_place/bowl_test_new_0/renders/
# num_points: 1024
# distractor_anchor_aug: False
# ball_radius: 0.1
# plane_standoff: 0.02
# gradient_clipping: 1 # 1 # 0 or blank (None) is don't clip






# distractor_anchor_rot_var: 180
# distractor_anchor_trans_var: 1



# grasp - use cloud_type=pre_grasp
# dataset_root: /home/jenny/data/taxpose/data/mug_grasp/train_data/renders
# test_dataset_root: /home/jenny/data/taxpose/data/mug_grasp/test_data/renders
# num_points: 1024
# distractor_anchor_aug: False
# ball_radius: 0.1
# plane_standoff: 0.04
# gradient_clipping: 1 # 1 # 0 or blank (None) is don't clip
# synthetic_occlusion: False


# placement
action_class: 0
anchor_class: 1
cloud_type: teleport


# grasping
# action_class: 2 
# anchor_class: 0
# cloud_type: pre_grasp

num_workers: 10
batch_size: 8
num_demo: null #12 # there are 12 demos in the 1 rack env. that's 24 for the 2 rack env
dataset_index: None
object_type: mug
action: place
dataset_size: 1000

use_all_validation_sets: False # Use 3 validations sets with SE(3), axis angle, and axis angle + uniform z transforms on the validation actions
# Consistent validation dataset settings
use_consistent_validation_set: True # Use hard coded validation dataset configuration
conval_rotation_variance: 180
conval_translation_variance: 0.5
conval_synthetic_occlusion: False
conval_scale_point_clouds: False
conval_action_rot_sample_method: "quat_uniform" # quat_uniform, axis_angle
conval_anchor_rot_sample_method: "random_flat_upright"
conval_distractor_rot_sample_method: "random_flat_upright"
conval_min_num_cameras: 4
conval_max_num_cameras: 4

# Training dataset settings
rotation_variance: 180
translation_variance: 0.5

action_occlusion_class: 0
action_plane_occlusion: True
action_ball_occlusion: False
action_bottom_surface_occlusion: False

anchor_occlusion_class: 1
anchor_plane_occlusion: False
anchor_ball_occlusion: True
anchor_bottom_surface_occlusion: False

bottom_surface_z_clipping_height: 0.01
skip_failed_occlusion: True
min_num_cameras: 4
max_num_cameras: 4
scale_point_clouds: False
scale_point_clouds_min: 1
scale_point_clouds_max: 1
use_class_labels: True

gripper_lr_label: False
overfit: False
overfit_distractor_aug: False
num_overfit_transforms: 1 #3
seed_overfit_transforms: True
set_Y_transform_to_identity: True
set_Y_transform_to_overfit: True
seed: 0
demo_mod_k_range_min: 2
demo_mod_k_range_max: 2
demo_mod_rot_var: 360
demo_mod_trans_var: 0.15
action_rot_sample_method: "quat_uniform" # quat_uniform, axis_angle
anchor_rot_sample_method: "random_flat_upright"
distractor_rot_sample_method: "random_flat_upright"
multimodal_transform_base: False # True

# Network Settings
center_feature: True
diff_emb: True
diff_transformer: True
emb_nn: dgcnn # Encoder network type used for the TAXPose decoder module
emb_dims: 512
latent_z_linear_size: 40
inital_sampling_ratio: 1
flow_compute_type: 0
residual_on: True
pred_weight: True
weight_normalize: softmax
sigmoid_on: True
softmax_temperature: 1
mlp: False
  #input_dims: 4 # set this within the script automatically
gumbel_temp: 1 #0.01 #5
division_smooth_factor: 1 #50
add_smooth_factor: 0.05
dropout_goal_emb: False

pzY_encoder_type: pn++
pzY_input_dims: 4
pzcondx_encoder_type: 2_dgcnn
pzX_input_dims: 3

min_err_across_racks_debug: True
error_mode_2rack: demo_rack
conditioning: pos_delta_l2norm # pos_delta_l2norm #latent_z_linear_internalcond # latent_z_1pred # pos_onehot #pos_delta_vec # latent_z # pos_delta_l2norm
use_action_z: True
taxpose_centering: z #z #z # mean, z
shuffle_for_pzX: False
hybrid_cond_logvar_limit: 5 # Limit the logvar of the hybrid conditioning using: limit * tanh(logvar), 0 to disable
hybrid_cond_regularize_all: True # Whether to regularize all per-point latents, or only the selected point's latent
hybrid_cond_pzX_regularize_all: True # During pzX training, whether to regularize all goal emb per point latents, or only the selected point's goal emb latent

return_flow_component: True 
flow_head_use_weighted_sum: True # Use weighted sum over the other pcd as the virtual correspondence
flow_head_use_selected_point_feature: False # When not doing weight sum, add the selected correspondences embedding to the respective action embedding
multilaterate: False # Requires return_flow_component to be True
mlat_sample: True # Sub-sample points for multilateration
mlat_nkps: 256 # Number of points to sample for multilateration
pred_mlat_weight: False # Predict weights for weighted multilateration
taxpose_conditioning_type: flow_fix-one_flow_head # [old, flow_fix, old-post_encoder, flow_fix-post_encoder, ...] replaces use_flow_weight_fix, post_encoder_conditioning
post_encoder_input_dims: 4 # Input dimensions for Taxpose encoder when using a post encoder conditioning

pzY_n_samples: 1 # How many samples to draw from the p(z|Y) encoder embedding during forward pass/inference (i.e. How many predictions to generate per input)
pzY_get_errors_across_samples: False # Calculate errors metrics across all samples (i.e. across all predictions for a given input)
pzY_use_debug_sampling_methods: False # Use debug sampling methods when getting errors across samples (i.e. 3 random samples, top 3 samples, and argmax sample)
pzX_n_samples: 1 # How many samples to draw from the p(z|X) encoder embedding during forward pass/inference (i.e. How many predictions to generate per input)
pzX_get_errors_across_samples: False # Calculate errors metrics across all samples (i.e. across all predictions for a given input)
pzX_use_debug_sampling_methods: False # Use debug sampling methods when getting errors across samples (i.e. 3 random samples, top 3 samples, and argmax sample)
pzX_use_pzY_z_samples: False # Use the p(z|Y) z samples during p(z|X) forward pass

pzY_transformer: none # Use transformer for conditional/joint prediction of action/anchor z [cross_object, none]
pzY_transformer_embnn_dims: 512 # Embedding network's embedding dimensions when using the transformer e.g. DGCNN encoder
pzY_transformer_emb_dims: 512 # Transformer network's embedding dimensions when using the transformer

pzX_transformer: cross_object # Use transformer for conditional/joint prediction of action/anchor z [cross_object, none]
pzX_transformer_embnn_dims: 512 # Embedding network's embedding dimensions when using the transformer e.g. DGCNN encoder
pzX_transformer_emb_dims: 512 # Transformer network's embedding dimensions when using the transformer

pzX_adversarial: False # Use adversarial training for p(z|X) encoder
pzX_adversarial_freeze_taxpose: False # Freeze the TAXPose model during p(z|X) adversarial training
discriminator_encoder_type: dgcnn # Encoder network type used for the discriminator network encoders
discriminator_input_dims: 4 # Input dimensions for the discriminator network encoders
discriminator_emb_dims: 256 # Embedding dimensions for the discriminator network encoders
discriminator_transformer_emb_dims: 256 # Transformer network's embedding dimensions when using the transformer
discriminator_mlp_hidden_dims: 256 # Hidden dimensions for the discriminator final mlps
discriminator_last_sigmoid: False # Use sigmoid activation on the last layer of the discriminator network

pzX_overwrite_loss: True # During pzX training, (False) add the goal emb. loss to the pzX loss or (True) overwrite the pzX loss with the goal emb. loss

# Loss Settings
flow_supervision: action2anchor
point_loss_type: 0
action_weight: 1
rotation_weight: 0
consistency_weight: 1
smoothness_weight: 0.1
#latent_weight: 0
vae_reg_loss_weight: 0 #1
goal_emb_cond_x_loss_weight: 1 #0.01
goal_emb_cond_x_loss_type: js_div # choose between [forward_kl, reverse_kl, js_div, js_div_eps0, js_div_mod_0_0, js_div_mod_eps0_0_0, js_div_mod_1e-1_1e-1, etc.]
pzY_joint_infonce_loss_weight: 0
pzX_joint_infonce_loss_weight: 0
spatial_distance_regularization_type: demo # Type of distance regularization, demo, pred, pred_sg
spatial_distance_regularization_weight: 0
generator_loss_weight: 1 # Weight for the generator during p(z|X) adversarial training
discriminator_loss_weight: 1 # Weight for the discriminator during p(z|X) adversarial training

# Training Settings

# checkpoint_file: #/home/jenny/data/equivariant_pose_graph/logs/residual_flow_occlusion/2023-08-25_164441/residual_flow_occlusion/wia2jdcr/checkpoints/epoch_999_global_step_125000.ckpt # /home/jenny/data/equivariant_pose_graph/logs/residual_flow_occlusion/2023-09-21_012835/residual_flow_occlusion/0gxxuz4a/checkpoints/epoch=552-step=69125.ckpt
checkpoint_file: null # /home/odonca/workspace/rpad/data/equivariant_pose_graph/logs/taxposed_rpdiff_mug-rack-multi/2024-01-27_005908/taxposed_rpdiff_mug-rack-multi/r94bfcqk/checkpoints/epoch_7960_global_step_995000.ckpt
resume_id: null

checkpoint_file_action: #/media/jenny/cubbins-archive/jwang_datasets/home_backup/jwang/code/taxpose/trained_models/pretraining_mug_embnn_weights.ckpt #trained_models/pretraining_mug_embnn_weights.ckpt
checkpoint_file_anchor: #/media/jenny/cubbins-archive/jwang_datasets/home_backup/jwang/code/taxpose/trained_models/pretraining_rack_embnn_weights.ckpt #trained_models/pretraining_rack_embnn_weights.ckpt
load_pretraining_for_taxpose: False #True
load_pretraining_for_conditioning: False #True
freeze_embnn: True
freeze_residual_flow: True
freeze_z_embnn: True
# p(z|X) is never frozen in these settings
init_cond_x: True
load_cond_x: False
joint_train_prior: True
joint_train_prior_freeze_embnn: True

max_steps: 1_000_000

# regular learning rate
lr: 1e-4 # 1e-4  #15e-6 #1e-6 #5e-5
# lr: 1e-3

# latent z linear learning rate
# lr: 1e-4 # 1e-5

# lower batch size
# lr: 1e-5

# note: "REDO [aug-inf env] p(z|X) where no rotations on demo in p(z|Y) 8/29/23"
note: "[2rack auginf] p(z|Y) and synthetic occlusions on 80% of time with uniform prior regularization"
