# Logging Settings
hydra: 
  run:
    dir: ${log_dir}/${experiment}/${now:%Y-%m-%d_%H%M%S}
  sweep:
    dir: ${log_dir}/${experiment}/sweep/${now:%Y-%m-%d_%H%M%S}
    subdir: ${hydra.job.num}

root_dir: # TODO fill in ex: /home/user/workspace/equivariant_pose_graph
log_dir: ${root_dir}/logs 
experiment: taxposed-icra2024
wandb_group: 1rack

image_logging_period: 1001
ckpt_save_freq: 5_000 # used to be 1_000
check_val_every_n_epoch: 5
plot_encoder_distribution: True

# Dataset Settings

# ACTION_CLASS = 0
# ANCHOR_CLASS = 1
# GRIPPER_CLASS = 2


dataset_root: ${root_dir}/data/bowl_place/bowl_train_data_ndf_cons_3/renders/
test_dataset_root: ${root_dir}/data/bowl_place/bowl_test_new_0/renders/

num_points: 1024
distractor_anchor_aug: False
ball_radius: 0.1
plane_standoff: 0.04
gradient_clipping: 0.001 # 0.001 # 1 # 0 or blank (None) is don't clip
synthetic_occlusion: 0.8

# grasping
action_class: 2 
anchor_class: 0
cloud_type: pre_grasp

num_workers: 10
batch_size: 8
num_demo: null #12 # there are 12 demos in the 1 rack env. that's 24 for the 2 rack env
dataset_index: None
dataset_size: 1000

use_all_validation_sets: False # Use 3 validations sets with SE(3), axis angle, and axis angle + uniform z transforms on the validation actions
# Consistent validation dataset settings
use_consistent_validation_set: True # Use hard coded validation dataset configuration
conval_rotation_variance: 180
conval_translation_variance: 0.5
conval_synthetic_occlusion: False
conval_scale_point_clouds: False
conval_action_rot_sample_method: "quat_uniform" # quat_uniform, axis_angle
conval_anchor_rot_sample_method: "random_flat_upright"
conval_distractor_rot_sample_method: "random_flat_upright"
conval_min_num_cameras: 4
conval_max_num_cameras: 4
conval_downsample_type: fps
conval_gaussian_noise_mu: 0
conval_gaussian_noise_std: 0

# Training dataset settings
downsample_type: random_0.5 # Either fps or random_X where X is the probability of downsampling with random indexing
rotation_variance: 180
translation_variance: 0.5
gaussian_noise_mu: 0 # Apply gaussian noise to the point cloud with mean mu and standard deviation std
gaussian_noise_std: 0.001 # Apply gaussian noise to the point cloud with mean mu and standard deviation std

action_plane_occlusion: True
action_ball_occlusion: False
action_bottom_surface_occlusion: False

anchor_plane_occlusion: False
anchor_ball_occlusion: True
anchor_bottom_surface_occlusion: False

bottom_surface_z_clipping_height: 0.01
min_num_cameras: 4
max_num_cameras: 4
scale_point_clouds: False
scale_point_clouds_min: 1.0
scale_point_clouds_max: 1.0

overfit: False
overfit_distractor_aug: False
num_overfit_transforms: 1 #3
seed_overfit_transforms: True
seed: 0
demo_mod_k_range_min: 2
demo_mod_k_range_max: 2
demo_mod_rot_var: 360
demo_mod_trans_var: 0.15
action_rot_sample_method: "quat_uniform" # quat_uniform, axis_angle
anchor_rot_sample_method: "random_flat_upright"
distractor_rot_sample_method: "random_flat_upright"

# Network Settings
center_feature: True
emb_nn: dgcnn # Encoder network type used for the TAXPose decoder module
emb_dims: 512
latent_z_linear_size: 40
residual_on: True
pred_weight: True
weight_normalize: softmax
sigmoid_on: True
softmax_temperature: 1
gumbel_temp: 1
add_smooth_factor: 0.05


# Settings for p(z|Y) and p(z|X) encoders
pzY_input_dims: 4
pzX_input_dims: 3


# General p(z|Y) and p(z|X) settings
min_err_across_racks_debug: True
error_mode_2rack: demo_rack
conditioning: pos_delta_l2norm
taxpose_centering: z
latent_z_cond_logvar_limit: 5 # Limit the logvar of the latent conditioning using: limit * tanh(logvar), 0 to disable


# Settings for TAXPose decoder
return_flow_component: True 
taxpose_conditioning_type: flow_fix-one_flow_head # [old, flow_fix, old-post_encoder, flow_fix-post_encoder, ...] replaces use_flow_weight_fix, post_encoder_conditioning


# Settings for transformer based p(z|X)
pzX_transformer_embnn_dims: 512 # Embedding network's embedding dimensions when using the transformer e.g. DGCNN encoder
pzX_transformer_emb_dims: 512 # Transformer network's embedding dimensions when using the transformer


pzX_overwrite_loss: True # During pzX training, (False) add the goal emb. loss to the pzX loss or (True) overwrite the pzX loss with the goal emb. loss


# Loss Settings
# Base TAXPose losses
flow_supervision: both
action_weight: 1
anchor_weight: 0
displace_weight: 1
consistency_weight: 1
smoothness_weight: 0.1
rotation_weight: 0

# Latent and prior losses
vae_reg_loss_weight: 1
goal_emb_cond_x_loss_weight: 1
goal_emb_cond_x_loss_type: js_div # choose between [forward_kl, reverse_kl, js_div, etc.]


# Training Settings
checkpoint_file: null
resume_id: null

checkpoint_file_action: # None
checkpoint_file_anchor: # None
load_pretraining_for_taxpose: False
load_pretraining_for_conditioning: False

# Enable all to train p(z|Y) separately from p(z|X) [default]
freeze_embnn: True # Freeze the TAXPose encoders
freeze_residual_flow: True # Freeze the entire TAXPose network 
freeze_z_embnn: True # Freeze p(z|Y) encoders

init_cond_x: True # Try to initialize p(z|X)
load_cond_x: False # Whether checkpoint file for p(z|X)

max_steps: 500_000

lr: 1e-4